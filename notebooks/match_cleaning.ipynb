{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7379a533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import df_stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb65880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you want to use the dataframe from df_stored\n",
    "#match = df_stored.match_df\n",
    "match_df = pd.read_csv('../data/raw/Match.csv')\n",
    "match_original_df = pd.read_csv('../data/raw/Match.csv')\n",
    "match_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0260f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = match_df.drop(columns=['PSH', 'PSD', 'PSA'], errors='ignore')\n",
    "match_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9871084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display non-empty (non-null) values from the 'goal' column\n",
    "non_empty_goals = match_df['goal'].dropna()\n",
    "print(non_empty_goals.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25aa1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_df = pd.read_csv('../data/raw/Team.csv')\n",
    "team_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeb949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge team_df to match_df to get home and away team long names\n",
    "match_df = match_df.merge(\n",
    "    team_df[['team_api_id', 'team_long_name']],\n",
    "    left_on='home_team_api_id',\n",
    "    right_on='team_api_id',\n",
    "    how='left'\n",
    ").rename(columns={'team_long_name': 'home_team_long_name'}).drop('team_api_id', axis=1)\n",
    "\n",
    "match_df = match_df.merge(\n",
    "    team_df[['team_api_id', 'team_long_name']],\n",
    "    left_on='away_team_api_id',\n",
    "    right_on='team_api_id',\n",
    "    how='left'\n",
    ").rename(columns={'team_long_name': 'away_team_long_name'}).drop('team_api_id', axis=1)\n",
    "\n",
    "# Show the first few rows with new columns\n",
    "match_df[['home_team_api_id', 'home_team_long_name', 'away_team_api_id', 'away_team_long_name']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd9ab58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(match_df.columns[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494ad897",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a60fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = match_df.drop(match_df.columns[11:55], axis=1)\n",
    "match_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a0d8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_player_cols = [f'home_player_{i}' for i in range(1, 12)]\n",
    "missing_counts = match_df[home_player_cols].isnull().sum()\n",
    "missing_percent = match_df[home_player_cols].isnull().mean() * 100\n",
    "\n",
    "stats_df = pd.DataFrame({\n",
    "    'missing_count': missing_counts,\n",
    "    'missing_percent': missing_percent\n",
    "})\n",
    "\n",
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cdb32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9997be32",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(match_df[home_player_cols].isnull(), cbar=False, cmap='viridis', yticklabels=False)\n",
    "plt.title('Missing Values Heatmap for Home Players 1-11')\n",
    "plt.xlabel('Home Player Columns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923e8865",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = match_df.dropna(subset=['home_team_long_name', 'away_team_long_name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of rows in match_df: {len(match_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6643c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_df = pd.read_csv('../data/cleaned/player_attributes_cleaned.csv')\n",
    "print(player_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c44f46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "\n",
    "# Prepare mapping from player_api_id to player_name and overall_rating\n",
    "# Keep the latest entry for each player_api_id (or you can use .max()/.min() as needed)\n",
    "player_info = player_df[['player_api_id', 'player_name', 'overall_rating']].drop_duplicates(subset=['player_api_id'], keep='last')\n",
    "\n",
    "# Create mapping dictionaries with unique indices\n",
    "player_name_map = player_info.set_index('player_api_id')['player_name']\n",
    "player_rating_map = player_info.set_index('player_api_id')['overall_rating']\n",
    "\n",
    "# Define player columns\n",
    "home_player_cols = [f'home_player_{i}' for i in range(1, 12)]\n",
    "away_player_cols = [f'away_player_{i}' for i in range(1, 12)]\n",
    "all_player_cols = home_player_cols + away_player_cols\n",
    "\n",
    "# Add player name and rating columns using .map()\n",
    "for col in all_player_cols:\n",
    "    match_df[f'{col}_name'] = match_df[col].map(player_name_map)\n",
    "    match_df[f'{col}_overall'] = match_df[col].map(player_rating_map)\n",
    "\n",
    "# Show the first few rows with new columns\n",
    "cols_to_show = []\n",
    "for col in all_player_cols:\n",
    "    cols_to_show.extend([col, f'{col}_name', f'{col}_overall'])\n",
    "#match_df[cols_to_show].tail()\n",
    "\n",
    "# ...existing code...\n",
    "\n",
    "# Remove duplicate columns by column name, keeping the last occurrence\n",
    "match_df = match_df.loc[:, ~match_df.columns.duplicated(keep='last')]\n",
    "\n",
    "# ...existing code...\n",
    "match_df[cols_to_show].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a8e8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "\n",
    "# List of league IDs to keep\n",
    "league_ids_to_keep = [1729, 4769, 7809, 10257, 21518]\n",
    "\n",
    "# Number of rows before filtering\n",
    "rows_before = len(match_df)\n",
    "\n",
    "# Filter the DataFrame\n",
    "match_df = match_df[match_df['league_id'].isin(league_ids_to_keep)]\n",
    "\n",
    "# Number of rows after filtering\n",
    "rows_after = len(match_df)\n",
    "\n",
    "print(f\"Rows before filtering: {rows_before}\")\n",
    "print(f\"Rows after filtering: {rows_after}\")\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e460ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count rows with any missing data\n",
    "missing_rows = match_df.isnull().any(axis=1).sum()\n",
    "print(f\"Number of rows with missing data: {missing_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570e76c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove specified columns if they exist\n",
    "cols_to_remove = ['goal', 'shoton', 'shotoff', 'foulcommit', 'card', 'cross', 'corner', 'possession']\n",
    "match_df = match_df.drop(columns=cols_to_remove, errors='ignore')\n",
    "match_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d8967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move all columns from 'B365H' to 'BSA' to the end of the DataFrame\n",
    "betting_start = match_df.columns.get_loc('B365H')\n",
    "betting_end = match_df.columns.get_loc('BSA') + 1  # +1 to include 'BSA'\n",
    "\n",
    "betting_cols = match_df.columns[betting_start:betting_end].tolist()\n",
    "other_cols = [col for col in match_df.columns if col not in betting_cols]\n",
    "\n",
    "# Reorder columns: all non-betting columns first, then betting columns\n",
    "match_df = match_df[other_cols + betting_cols]\n",
    "match_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b52dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print total number of rows\n",
    "total_rows = len(match_df)\n",
    "print(f\"Total number of rows: {total_rows}\")\n",
    "\n",
    "# Calculate and print percent of rows with missing data\n",
    "missing_rows = match_df.isnull().any(axis=1).sum()\n",
    "percent_missing = (missing_rows / total_rows) * 100\n",
    "print(f\"Percent of rows with missing data: {percent_missing:.2f}%\")\n",
    "match_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafe0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the range of betting columns\n",
    "betting_start = match_df.columns.get_loc('B365H')\n",
    "betting_end = match_df.columns.get_loc('BSA') + 1  # +1 to include 'BSA'\n",
    "betting_cols = match_df.columns[betting_start:betting_end].tolist()\n",
    "\n",
    "# All columns except betting columns\n",
    "non_betting_cols = [col for col in match_df.columns if col not in betting_cols]\n",
    "\n",
    "# Count rows with missing data in non-betting columns\n",
    "missing_non_betting = match_df[non_betting_cols].isnull().any(axis=1).sum()\n",
    "print(f\"Rows with missing data (excluding betting columns): {missing_non_betting}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1a58ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Italy (league_id=10257) and France (league_id=4769) leagues\n",
    "match_df = match_df[~match_df['league_id'].isin([10257, 4769])]\n",
    "\n",
    "# Get the range of betting columns\n",
    "betting_start = match_df.columns.get_loc('B365H')\n",
    "betting_end = match_df.columns.get_loc('BSA') + 1  # +1 to include 'BSA'\n",
    "betting_cols = match_df.columns[betting_start:betting_end].tolist()\n",
    "\n",
    "# All columns except betting columns\n",
    "non_betting_cols = [col for col in match_df.columns if col not in betting_cols]\n",
    "\n",
    "# Count rows with missing data in non-betting columns\n",
    "missing_non_betting = match_df[non_betting_cols].isnull().any(axis=1).sum()\n",
    "print(f\"Rows with missing data (excluding betting columns, after removing Italy and France): {missing_non_betting}\")\n",
    "# Print total number of rows after removing Italy and France\n",
    "print(f\"Total number of rows:   {len(match_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e2efe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the exact betting columns from 'B365H' to 'BSA'\n",
    "betting_start = match_df.columns.get_loc('B365H')\n",
    "betting_end = match_df.columns.get_loc('BSA') + 1  # +1 to include 'BSA'\n",
    "betting_cols = match_df.columns[betting_start:betting_end].tolist()\n",
    "\n",
    "# Home, draw, and away columns within the betting odds range only\n",
    "home_cols = [col for col in betting_cols if col.endswith('H')]\n",
    "draw_cols = [col for col in betting_cols if col.endswith('D')]\n",
    "away_cols = [col for col in betting_cols if col.endswith('A')]\n",
    "\n",
    "# Calculate the median for each row for home, draw, and away odds (using only B365H to BSA columns)\n",
    "match_df['betting_median_home'] = match_df[home_cols].median(axis=1, skipna=True)\n",
    "match_df['betting_median_draw'] = match_df[draw_cols].median(axis=1, skipna=True)\n",
    "match_df['betting_median_away'] = match_df[away_cols].median(axis=1, skipna=True)\n",
    "\n",
    "# Calculate probabilities based on the median odds\n",
    "inv_home = 1 / match_df['betting_median_home']\n",
    "inv_draw = 1 / match_df['betting_median_draw']\n",
    "inv_away = 1 / match_df['betting_median_away']\n",
    "inv_sum = inv_home + inv_draw + inv_away\n",
    "\n",
    "match_df['prob_home'] = inv_home / inv_sum\n",
    "match_df['prob_draw'] = inv_draw / inv_sum\n",
    "match_df['prob_away'] = inv_away\n",
    "\n",
    "match_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d0f7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define player columns for home and away (1-11)\n",
    "home_player_cols = [f'home_player_{i}' for i in range(1, 12)]\n",
    "away_player_cols = [f'away_player_{i}' for i in range(1, 12)]\n",
    "all_player_cols = home_player_cols + away_player_cols\n",
    "\n",
    "# Total number of player slots (rows * 22)\n",
    "total_player_slots = len(match_df) * len(all_player_cols)\n",
    "\n",
    "# Total number of missing player slots\n",
    "missing_players = match_df[all_player_cols].isnull().sum().sum()\n",
    "\n",
    "# Percentage of missing player slots\n",
    "percent_missing_players = (missing_players / total_player_slots) * 100\n",
    "print(f\"Percentage of missing player slots: {percent_missing_players:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ebe015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all rows with any missing player slots (home_player_1-11 and away_player_1-11)\n",
    "home_player_cols = [f'home_player_{i}' for i in range(1, 12)]\n",
    "away_player_cols = [f'away_player_{i}' for i in range(1, 12)]\n",
    "all_player_cols = home_player_cols + away_player_cols\n",
    "\n",
    "match_df = match_df.dropna(subset=all_player_cols)\n",
    "print(f\"Rows remaining after dropping missing player slots: {len(match_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdfa087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate percent of rows with missing data before column 'B365H'\n",
    "b365h_idx = match_df.columns.get_loc('B365H')\n",
    "cols_before_b365h = match_df.columns[:b365h_idx]\n",
    "\n",
    "missing_rows = match_df[cols_before_b365h].isnull().any(axis=1).sum()\n",
    "percent_missing = (missing_rows / len(match_df)) * 100\n",
    "print(f\"Percent of rows with missing data before 'B365H': {percent_missing:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3f7fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show which columns before 'B365H' have missing data and how many missing values per column\n",
    "b365h_idx = match_df.columns.get_loc('B365H')\n",
    "cols_before_b365h = match_df.columns[:b365h_idx]\n",
    "\n",
    "missing_counts = match_df[cols_before_b365h].isnull().sum()\n",
    "missing_cols = missing_counts[missing_counts > 0]\n",
    "print(\"Columns before 'B365H' with missing data and their counts:\")\n",
    "print(missing_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380d0493",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ef137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df.to_csv('../data/cleaned/match_df_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
